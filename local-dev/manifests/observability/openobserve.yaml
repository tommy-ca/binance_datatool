---
# OpenObserve Unified Observability Platform
# Replaces Prometheus + Grafana + Jaeger with single solution
# Crypto Lakehouse Local Development Environment
apiVersion: v1
kind: ConfigMap
metadata:
  name: openobserve-config
  namespace: observability
data:
  config.yaml: |
    # OpenObserve Configuration for Crypto Lakehouse
    server:
      host: "0.0.0.0"
      port: 5080
      
    storage:
      type: "s3"
      s3:
        bucket: "crypto-lakehouse-logs"
        endpoint: "http://minio-service.minio:9000"
        access_key_id: "minioadmin"
        secret_access_key: "minioadmin123"
        region: "us-east-1"
        path_style: true
        
    ingestor:
      otlp:
        grpc:
          enabled: true
          port: 4317
        http:
          enabled: true
          port: 4318
      prometheus:
        enabled: true
        port: 9090
      jaeger:
        enabled: true
        grpc_port: 14250
        http_port: 14268
        
    query:
      max_results: 10000
      timeout: "30s"
      
    auth:
      enabled: true
      root_user_email: "admin@crypto-lakehouse.local"
      root_user_password: "admin123"
      
    common:
      cluster_name: "crypto-lakehouse-local"
      environment: "development"
      
  # Pre-configured dashboard for crypto lakehouse metrics
  crypto-dashboard.json: |
    {
      "dashboard": {
        "id": "crypto-lakehouse-overview",
        "title": "Crypto Lakehouse - Local Development Overview",
        "description": "Unified observability for Prefect, MinIO, and s5cmd operations",
        "version": 1,
        "type": "dashboard",
        "panels": [
          {
            "id": 1,
            "title": "System Health Overview",
            "type": "stat",
            "targets": [
              {
                "expr": "up",
                "legendFormat": "{{service_name}} - {{instance}}"
              }
            ],
            "fieldConfig": {
              "defaults": {
                "color": {
                  "mode": "thresholds"
                },
                "mappings": [],
                "thresholds": {
                  "steps": [
                    {"color": "red", "value": 0},
                    {"color": "green", "value": 1}
                  ]
                }
              }
            }
          },
          {
            "id": 2,
            "title": "s5cmd Operations Rate",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(s5cmd_operations_total[5m])",
                "legendFormat": "Operations/sec - {{operation}}"
              }
            ]
          },
          {
            "id": 3,
            "title": "s5cmd Throughput",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(s5cmd_bytes_transferred_total[5m]) / 1024 / 1024",
                "legendFormat": "Throughput MB/s"
              }
            ]
          },
          {
            "id": 4,
            "title": "Prefect Workflow Status",
            "type": "timeseries",
            "targets": [
              {
                "expr": "prefect_workflow_runs_running_total",
                "legendFormat": "Running Workflows"
              },
              {
                "expr": "rate(prefect_workflow_runs_completed_total[5m])",
                "legendFormat": "Completed/sec"
              }
            ]
          },
          {
            "id": 5,
            "title": "MinIO Storage Utilization",
            "type": "gauge",
            "targets": [
              {
                "expr": "(minio_cluster_capacity_usable_total_bytes - minio_cluster_capacity_usable_free_bytes) / minio_cluster_capacity_usable_total_bytes * 100",
                "legendFormat": "Storage Used %"
              }
            ]
          },
          {
            "id": 6,
            "title": "Error Rate Analysis",
            "type": "timeseries",
            "targets": [
              {
                "expr": "rate(s5cmd_operations_total{status=\"error\"}[5m])",
                "legendFormat": "s5cmd Errors/sec"
              },
              {
                "expr": "rate(prefect_workflow_runs_total{status=\"failed\"}[5m])",
                "legendFormat": "Prefect Failures/sec"
              }
            ]
          }
        ],
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "refresh": "30s"
      }
    }

---
# OpenObserve StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: openobserve
  namespace: observability
  labels:
    app: openobserve
    component: unified-observability
spec:
  serviceName: openobserve
  replicas: 1
  selector:
    matchLabels:
      app: openobserve
  template:
    metadata:
      labels:
        app: openobserve
        component: unified-observability
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "5080"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: openobserve
        image: public.ecr.aws/zinclabs/openobserve:latest-simd
        ports:
        - containerPort: 5080
          name: web
        - containerPort: 4317
          name: otlp-grpc
        - containerPort: 4318
          name: otlp-http
        - containerPort: 9090
          name: prometheus
        - containerPort: 14250
          name: jaeger-grpc
        - containerPort: 14268
          name: jaeger-http
        env:
        - name: ZO_ROOT_USER_EMAIL
          value: "admin@crypto-lakehouse.local"
        - name: ZO_ROOT_USER_PASSWORD
          value: "admin123"
        - name: ZO_DATA_DIR
          value: "/data"
        - name: ZO_LOCAL_MODE
          value: "false"
        - name: ZO_LOCAL_MODE_STORAGE
          value: "s3"
        - name: ZO_S3_BUCKET_NAME
          value: "crypto-lakehouse-logs"
        - name: ZO_S3_REGION_NAME
          value: "us-east-1"
        - name: ZO_S3_ENDPOINT
          value: "http://minio-service.minio:9000"
        - name: ZO_S3_ACCESS_KEY_ID
          value: "minioadmin"
        - name: ZO_S3_SECRET_ACCESS_KEY
          value: "minioadmin123"
        - name: ZO_S3_PROVIDER
          value: "minio"
        - name: ZO_TELEMETRY
          value: "false"
        - name: ZO_TELEMETRY_URL
          value: ""
        - name: ZO_WEB_URL
          value: "http://localhost:5080"
        - name: ZO_BASE_URI
          value: ""
        - name: ZO_INSTANCE_NAME
          value: "crypto-lakehouse-local"
        - name: ZO_NODE_ROLE
          value: "all"
        - name: ZO_CLUSTER_NAME
          value: "crypto-lakehouse-local"
        - name: ZO_PROMETHEUS_ENABLED
          value: "true"
        - name: ZO_JAEGER_ENABLED
          value: "true"
        - name: ZO_OTLP_GRPC_ENABLED
          value: "true"
        - name: ZO_OTLP_HTTP_ENABLED
          value: "true"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2000m
            memory: 2Gi
        volumeMounts:
        - name: data
          mountPath: /data
        - name: config
          mountPath: /etc/openobserve
        livenessProbe:
          httpGet:
            path: /healthz
            port: 5080
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /healthz
            port: 5080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: config
        configMap:
          name: openobserve-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-storage
      resources:
        requests:
          storage: 10Gi

---
# OpenObserve Service
apiVersion: v1
kind: Service
metadata:
  name: openobserve
  namespace: observability
  labels:
    app: openobserve
    component: unified-observability
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "5080"
    prometheus.io/path: "/metrics"
spec:
  selector:
    app: openobserve
  ports:
  - name: web
    port: 5080
    targetPort: 5080
    protocol: TCP
  - name: otlp-grpc
    port: 4317
    targetPort: 4317
    protocol: TCP
  - name: otlp-http
    port: 4318
    targetPort: 4318
    protocol: TCP
  - name: prometheus
    port: 9090
    targetPort: 9090
    protocol: TCP
  - name: jaeger-grpc
    port: 14250
    targetPort: 14250
    protocol: TCP
  - name: jaeger-http
    port: 14268
    targetPort: 14268
    protocol: TCP
  type: ClusterIP

---
# OpenObserve Ingress (for external access)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: openobserve-ingress
  namespace: observability
  labels:
    app: openobserve
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - host: openobserve.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: openobserve
            port:
              number: 5080

---
# ServiceMonitor for OpenObserve (if using Prometheus Operator)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: openobserve
  namespace: observability
  labels:
    app: openobserve
spec:
  selector:
    matchLabels:
      app: openobserve
  endpoints:
  - port: web
    interval: 30s
    path: /metrics

---
# ConfigMap for OpenObserve initialization scripts
apiVersion: v1
kind: ConfigMap
metadata:
  name: openobserve-init
  namespace: observability
data:
  init.sh: |
    #!/bin/bash
    set -euo pipefail
    
    echo "Initializing OpenObserve for Crypto Lakehouse..."
    
    # Wait for OpenObserve to be ready
    until curl -sf http://openobserve.observability:5080/healthz; do
      echo "Waiting for OpenObserve to be ready..."
      sleep 5
    done
    
    echo "OpenObserve is ready!"
    
    # Create organization and stream if needed
    # This would typically be done via API calls
    echo "OpenObserve initialization completed"

---
# Init Job for OpenObserve setup
apiVersion: batch/v1
kind: Job
metadata:
  name: openobserve-init
  namespace: observability
  labels:
    app: openobserve-init
    component: initialization
spec:
  template:
    metadata:
      labels:
        app: openobserve-init
        component: initialization
    spec:
      restartPolicy: OnFailure
      containers:
      - name: init
        image: curlimages/curl:8.4.0
        command: ["/bin/sh"]
        args: ["/scripts/init.sh"]
        volumeMounts:
        - name: init-scripts
          mountPath: /scripts
      volumes:
      - name: init-scripts
        configMap:
          name: openobserve-init
          defaultMode: 0755